{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install bonita first\n",
    "# !pip install -e git+https://github.com/BatsResearch/bonito#egg=bonito"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can start by downloading all our documentation from our Gitbook docs located\n",
    "at docs.zenml.io. We'll use the langchain scraper to make this easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mCould not import GCP service connector: No module named 'google.api_core'.\u001b[0m\n",
      "\u001b[33mCould not import Azure service connector: No module named 'azure.identity'.\u001b[0m\n",
      "\u001b[33mCould not import Kubernetes service connector: No module named 'kubernetes'.\u001b[0m\n",
      "\u001b[33mCould not import HyperAI service connector: No module named 'paramiko'.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from zenml.client import Client\n",
    "\n",
    "artifact = Client().get_artifact_version('86ba966e-66d1-4c79-a464-8bfff65300a0')\n",
    "loaded_artifact = artifact.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭─────────────────────────────── </span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">class</span><span style=\"color: #000000; text-decoration-color: #000000\"> </span><span style=\"color: #008000; text-decoration-color: #008000\">'langchain_core.documents.base.Document'</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">&gt;</span><span style=\"color: #000080; text-decoration-color: #000080\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008080; text-decoration-color: #008080\">Class for storing a piece of text and associated metadata.</span>                                                      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────╮</span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Document</span><span style=\"font-weight: bold\">(</span>                                                                                                   <span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">page_content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'An end-to-end project\\n\\nPut your new knowledge in action with'</span>+<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2253</span>,                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://docs.zenml.io/user-guide/production-guide/end-to-end'</span><span style=\"font-weight: bold\">}</span>                     <span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"font-weight: bold\">)</span>                                                                                                           <span style=\"color: #008000; text-decoration-color: #008000\">│</span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #008000; text-decoration-color: #008000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-style: italic\">lc_attributes</span> = <span style=\"font-weight: bold\">{}</span>                                                                                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>    <span style=\"color: #808000; text-decoration-color: #808000; font-style: italic\">lc_secrets</span> = <span style=\"font-weight: bold\">{}</span>                                                                                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>      <span style=\"color: #808000; text-decoration-color: #808000; font-style: italic\">metadata</span> = <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'source'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'https://docs.zenml.io/user-guide/production-guide/end-to-end'</span><span style=\"font-weight: bold\">}</span>                      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #808000; text-decoration-color: #808000; font-style: italic\">page_content</span> = <span style=\"color: #008000; text-decoration-color: #008000\">'An end-to-end project\\n\\nPut your new knowledge in action with an end-to-end project\\n\\nThat </span>  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                 <span style=\"color: #008000; text-decoration-color: #008000\">was awesome! We learned so many advanced MLOps production concepts:\\n\\nThe value of deploying </span>  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                 <span style=\"color: #008000; text-decoration-color: #008000\">ZenML\\u200b\\n\\nAbstracting infrastructure configuration into stacks\\u200b\\n\\n\\u200bConnecting </span>  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                 <span style=\"color: #008000; text-decoration-color: #008000\">remote storage\\u200b\\n\\n\\u200bOrchestrating on the cloud\\u200b\\n\\n\\u200bConfiguring the </span>        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                 <span style=\"color: #008000; text-decoration-color: #008000\">pipeline to scale compute\\u200b\\n\\n\\u200bConnecting a git repository\\u200b\\n\\nWe will now </span>      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                 <span style=\"color: #008000; text-decoration-color: #008000\">combine all of these concepts into an end-to-end MLOps project powered by ZenML.\\n\\nGet </span>        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                 <span style=\"color: #008000; text-decoration-color: #008000\">started\\n\\nStart with a fresh virtual environment with no dependencies. Then let\\'s install our</span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                 <span style=\"color: #008000; text-decoration-color: #008000\">dependencies:\\n\\npip install \"zenml[templates,server]\" notebook\\n\\nzenml integration install </span>   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                 <span style=\"color: #008000; text-decoration-color: #008000\">sklearn -y\\n\\nWe will then use\\n\\nZenML templates\\n\\nto help us get the code we need for the </span>   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                 <span style=\"color: #008000; text-decoration-color: #008000\">project:\\n\\nmkdir zenml_batch_e2e\\n\\ncd zenml_batch_e2e\\n\\nzenml init --template e2e_batch </span>     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                 <span style=\"color: #008000; text-decoration-color: #008000\">--template-with-defaults\\n\\n# Just in case, we install the requirements again\\n\\npip install -r</span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                 <span style=\"color: #008000; text-decoration-color: #008000\">requirements.txt\\n\\nAbove doesn\\'t work? Here is an alternative\\n\\nThe e2e template is also </span>    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                 <span style=\"color: #008000; text-decoration-color: #008000\">available as a\\n\\nZenML example\\n\\n. You can clone it:\\n\\ngit clone </span>                            <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                 <span style=\"color: #008000; text-decoration-color: #008000\">[email\\xa0protected]:zenml-io/zenml.git\\n\\ncd examples/e2e\\n\\npip install -r </span>                   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                 <span style=\"color: #008000; text-decoration-color: #008000\">requirements.txt\\n\\nzenml init\\n\\nWhat you\\'ll learn\\n\\nThe e2e project is a comprehensive </span>     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                 <span style=\"color: #008000; text-decoration-color: #008000\">project template to cover major use cases of ZenML: a collection of steps and pipelines and, to</span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                 <span style=\"color: #008000; text-decoration-color: #008000\">top it all off, a simple but useful CLI. It showcases the core ZenML concepts for supervised ML</span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                 <span style=\"color: #008000; text-decoration-color: #008000\">with batch predictions. It builds on top of the\\n\\nstarter project\\n\\nwith more advanced </span>       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                 <span style=\"color: #008000; text-decoration-color: #008000\">concepts.\\n\\nAs you progress through the e2e batch template, try running the pipelines on </span>      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                 <span style=\"color: #008000; text-decoration-color: #008000\">a\\n\\nremote cloud stack\\n\\non a tracked\\n\\ngit repository\\n\\nto practice some of the concepts </span>  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                 <span style=\"color: #008000; text-decoration-color: #008000\">we have learned in this guide.\\n\\nAt the end, don\\'t forget to share the\\n\\nZenML e2e </span>          <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                 <span style=\"color: #008000; text-decoration-color: #008000\">template\\n\\nwith your colleagues and see how they react!\\n\\nConclusion and next steps\\n\\nThe </span>   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                 <span style=\"color: #008000; text-decoration-color: #008000\">production guide has now hopefully landed you with an end-to-end MLOps project, powered by a </span>   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                 <span style=\"color: #008000; text-decoration-color: #008000\">ZenML server connected to your cloud infrastructure. You are now ready to dive deep into </span>       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                 <span style=\"color: #008000; text-decoration-color: #008000\">writing your own pipelines and stacks. If you are looking to learn more advanced concepts, </span>     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                 <span style=\"color: #008000; text-decoration-color: #008000\">the\\n\\nAdvanced Guide\\n\\nis for you. Until then, we wish you the best of luck chasing your </span>     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                 <span style=\"color: #008000; text-decoration-color: #008000\">MLOps dreams!\\n\\nPreviousConfigure a code repository\\n\\nNext - User GuideAdvanced guide\\n\\nLast</span> <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                 <span style=\"color: #008000; text-decoration-color: #008000\">modified \\n\\n13d ago'</span>                                                                           <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>          <span style=\"color: #808000; text-decoration-color: #808000; font-style: italic\">type</span> = <span style=\"color: #008000; text-decoration-color: #008000\">'Document'</span>                                                                                      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m──────────────────────────────\u001b[0m\u001b[34m \u001b[0m\u001b[1;34m<\u001b[0m\u001b[1;95mclass\u001b[0m\u001b[39m \u001b[0m\u001b[32m'langchain_core.documents.base.Document'\u001b[0m\u001b[1;34m>\u001b[0m\u001b[34m \u001b[0m\u001b[34m───────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[36mClass for storing a piece of text and associated metadata.\u001b[0m                                                      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[32m╭─────────────────────────────────────────────────────────────────────────────────────────────────────────────╮\u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[32m│\u001b[0m \u001b[1;35mDocument\u001b[0m\u001b[1m(\u001b[0m                                                                                                   \u001b[32m│\u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[32m│\u001b[0m \u001b[2;32m│   \u001b[0m\u001b[33mpage_content\u001b[0m=\u001b[32m'An end-to-end project\\n\\nPut your new knowledge in action with'\u001b[0m+\u001b[1;36m2253\u001b[0m,                     \u001b[32m│\u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[32m│\u001b[0m \u001b[2;32m│   \u001b[0m\u001b[33mmetadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://docs.zenml.io/user-guide/production-guide/end-to-end'\u001b[0m\u001b[1m}\u001b[0m                     \u001b[32m│\u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[32m│\u001b[0m \u001b[1m)\u001b[0m                                                                                                           \u001b[32m│\u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[32m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m \u001b[3;33mlc_attributes\u001b[0m = \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m                                                                                              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m    \u001b[3;33mlc_secrets\u001b[0m = \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m                                                                                              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m      \u001b[3;33mmetadata\u001b[0m = \u001b[1m{\u001b[0m\u001b[32m'source'\u001b[0m: \u001b[32m'https://docs.zenml.io/user-guide/production-guide/end-to-end'\u001b[0m\u001b[1m}\u001b[0m                      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[3;33mpage_content\u001b[0m = \u001b[32m'An end-to-end project\\n\\nPut your new knowledge in action with an end-to-end project\\n\\nThat \u001b[0m  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                 \u001b[32mwas awesome! We learned so many advanced MLOps production concepts:\\n\\nThe value of deploying \u001b[0m  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                 \u001b[32mZenML\\u200b\\n\\nAbstracting infrastructure configuration into stacks\\u200b\\n\\n\\u200bConnecting \u001b[0m  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                 \u001b[32mremote storage\\u200b\\n\\n\\u200bOrchestrating on the cloud\\u200b\\n\\n\\u200bConfiguring the \u001b[0m        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                 \u001b[32mpipeline to scale compute\\u200b\\n\\n\\u200bConnecting a git repository\\u200b\\n\\nWe will now \u001b[0m      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                 \u001b[32mcombine all of these concepts into an end-to-end MLOps project powered by ZenML.\\n\\nGet \u001b[0m        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                 \u001b[32mstarted\\n\\nStart with a fresh virtual environment with no dependencies. Then let\\'s install our\u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                 \u001b[32mdependencies:\\n\\npip install \"zenml\u001b[0m\u001b[32m[\u001b[0m\u001b[32mtemplates,server\u001b[0m\u001b[32m]\u001b[0m\u001b[32m\" notebook\\n\\nzenml integration install \u001b[0m   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                 \u001b[32msklearn -y\\n\\nWe will then use\\n\\nZenML templates\\n\\nto help us get the code we need for the \u001b[0m   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                 \u001b[32mproject:\\n\\nmkdir zenml_batch_e2e\\n\\ncd zenml_batch_e2e\\n\\nzenml init --template e2e_batch \u001b[0m     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                 \u001b[32m--template-with-defaults\\n\\n# Just in case, we install the requirements again\\n\\npip install -r\u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                 \u001b[32mrequirements.txt\\n\\nAbove doesn\\'t work? Here is an alternative\\n\\nThe e2e template is also \u001b[0m    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                 \u001b[32mavailable as a\\n\\nZenML example\\n\\n. You can clone it:\\n\\ngit clone \u001b[0m                            \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                 \u001b[32m[\u001b[0m\u001b[32memail\\xa0protected\u001b[0m\u001b[32m]\u001b[0m\u001b[32m:zenml-io/zenml.git\\n\\ncd examples/e2e\\n\\npip install -r \u001b[0m                   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                 \u001b[32mrequirements.txt\\n\\nzenml init\\n\\nWhat you\\'ll learn\\n\\nThe e2e project is a comprehensive \u001b[0m     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                 \u001b[32mproject template to cover major use cases of ZenML: a collection of steps and pipelines and, to\u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                 \u001b[32mtop it all off, a simple but useful CLI. It showcases the core ZenML concepts for supervised ML\u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                 \u001b[32mwith batch predictions. It builds on top of the\\n\\nstarter project\\n\\nwith more advanced \u001b[0m       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                 \u001b[32mconcepts.\\n\\nAs you progress through the e2e batch template, try running the pipelines on \u001b[0m      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                 \u001b[32ma\\n\\nremote cloud stack\\n\\non a tracked\\n\\ngit repository\\n\\nto practice some of the concepts \u001b[0m  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                 \u001b[32mwe have learned in this guide.\\n\\nAt the end, don\\'t forget to share the\\n\\nZenML e2e \u001b[0m          \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                 \u001b[32mtemplate\\n\\nwith your colleagues and see how they react!\\n\\nConclusion and next steps\\n\\nThe \u001b[0m   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                 \u001b[32mproduction guide has now hopefully landed you with an end-to-end MLOps project, powered by a \u001b[0m   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                 \u001b[32mZenML server connected to your cloud infrastructure. You are now ready to dive deep into \u001b[0m       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                 \u001b[32mwriting your own pipelines and stacks. If you are looking to learn more advanced concepts, \u001b[0m     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                 \u001b[32mthe\\n\\nAdvanced Guide\\n\\nis for you. Until then, we wish you the best of luck chasing your \u001b[0m     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                 \u001b[32mMLOps dreams!\\n\\nPreviousConfigure a code repository\\n\\nNext - User GuideAdvanced guide\\n\\nLast\u001b[0m \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                 \u001b[32mmodified \\n\\n13d ago'\u001b[0m                                                                           \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m          \u001b[3;33mtype\u001b[0m = \u001b[32m'Document'\u001b[0m                                                                                      \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rich import inspect\n",
    "\n",
    "inspect(loaded_artifact[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['An end-to-end project\\n\\nPut your new knowledge in action with an end-to-end project\\n\\nThat was awesome!',\n",
       " 'We learned so many advanced MLOps production concepts:\\n\\nThe value of deploying ZenML\\u200b\\n\\nAbstracting infrastructure configuration into stacks\\u200b\\n\\n\\u200bConnecting remote storage\\u200b\\n\\n\\u200bOrchestrating on the cloud\\u200b\\n\\n\\u200bConfiguring the pipeline to scale compute\\u200b\\n\\n\\u200bConnecting a git repository\\u200b\\n\\nWe will now combine all of these concepts into an end-to-end MLOps project powered by ZenML.',\n",
       " 'Get started\\n\\nStart with a fresh virtual environment with no dependencies.',\n",
       " 'Then let\\'s install our dependencies:\\n\\npip install \"zenml[templates,server]\" notebook\\n\\nzenml integration install sklearn -y\\n\\nWe will then use\\n\\nZenML templates\\n\\nto help us get the code we need for the project:',\n",
       " \"mkdir zenml_batch_e2e\\n\\ncd zenml_batch_e2e\\n\\nzenml init --template e2e_batch --template-with-defaults\\n\\n# Just in case, we install the requirements again\\n\\npip install -r requirements.txt\\n\\nAbove doesn't work?\"]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")  # Load the English language model\n",
    "\n",
    "def split_into_sentences(text):\n",
    "    doc = nlp(text)  # Process the text with SpaCy\n",
    "    sentences = [sent.text.strip() for sent in doc.sents]  # Extract sentences and strip whitespace\n",
    "    return sentences\n",
    "\n",
    "def process_documents(documents):\n",
    "    all_sentences = []\n",
    "    for doc in documents:\n",
    "        text = doc.page_content  # Extract the text from the Document object\n",
    "        sentences = split_into_sentences(text)  # Split the text into sentences\n",
    "        all_sentences.extend(sentences)  # Add the sentences to the list\n",
    "    return all_sentences\n",
    "\n",
    "  # Your list of langchain Document objects\n",
    "sentences = process_documents(loaded_artifact)  # Process the documents and get all sentences\n",
    "sentences[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;35mPyTorch version 2.1.2 available.\u001b[0m\n",
      "Dataset({\n",
      "    features: ['sentence'],\n",
      "    num_rows: 8192\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# Assuming sentences is a list of strings, where each string is a sentence\n",
    "data = {\"sentence\": sentences}\n",
    "dataset = Dataset.from_dict(data)\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/BatsResearch/bonito.git\n",
    "# %pip install -e bonito"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 03-19 18:21:45 llm_engine.py:70] Initializing an LLM engine with config: model='BatsResearch/bonito-v1', tokenizer='BatsResearch/bonito-v1', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=10000, download_dir=None, load_format=auto, tensor_parallel_size=1, quantization=None, enforce_eager=False, seed=0)\n",
      "INFO 03-19 18:21:52 llm_engine.py:275] # GPU blocks: 3023, # CPU blocks: 2048\n",
      "INFO 03-19 18:21:54 model_runner.py:501] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 03-19 18:21:54 model_runner.py:505] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode.\n",
      "INFO 03-19 18:22:00 model_runner.py:547] Graph capturing finished in 6 secs.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8376c32d5dcb41c6a01819367de2d7a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8192 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|██████████| 8192/8192 [02:59<00:00, 45.68it/s] \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b418bf274a64b84a032fe1bd7b2954a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/8192 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b55ffe74aff4e5da9d2965cf7707ecf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8155 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bonito import Bonito, SamplingParams\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Initialize the Bonito model\n",
    "bonito = Bonito(\"BatsResearch/bonito-v1\", max_model_len=10000)\n",
    "\n",
    "sampling_params = SamplingParams(max_tokens=256, top_p=0.95, temperature=0.5, n=1)\n",
    "synthetic_dataset = bonito.generate_tasks(\n",
    "    dataset,\n",
    "    context_col=\"sentence\",\n",
    "    task_type=\"exqa\",\n",
    "    sampling_params=sampling_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'output'],\n",
       "    num_rows: 8155\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthetic_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repository URL: https://huggingface.co/datasets/strickvl/synth-test-zenml-exqa\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a89424962a7e4e33a0085a53008ca4f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bca4caebf17f4f32b33b9c9be37ac39a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/strickvl/synth-test-zenml-exqa/commit/4d5602177c09744c7395eb0d87e53f4333d269b7', commit_message='Upload dataset', commit_description='', oid='4d5602177c09744c7395eb0d87e53f4333d269b7', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import create_repo\n",
    "from huggingface_hub import Repository\n",
    "\n",
    "repo_name = \"synth-test-zenml-exqa\"\n",
    "repo_url = create_repo(repo_name, repo_type=\"dataset\")\n",
    "print(\"Repository URL:\", repo_url)\n",
    "synthetic_dataset.push_to_hub(f\"strickvl/{repo_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
